{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ChatGPT-4 API for Image Text Extraction and Question Answering\n",
    "\n",
    "This notebook demonstrates how to use the ChatGPT-4 API to extract information from an image, such as the bounding boxes and the text within those boxes. We will also show how to ask questions about the content of the image, for example, information contained in a document.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, we need to install the required libraries. You can install them using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your API key!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visit this [link](https://platform.openai.com/settings/profile?tab=api-keys) to get your API key.\n",
    "2. Press \"+ Create new secret key\" to create a new API key.\n",
    "3. Fill in the name of the key and (optional) configure the permissions as shown in the image below. Then press \"Create\" to create the key.\n",
    "   \n",
    "<img src=\"../assets/tutorials/create_new_secret_key_dialog.png\" alt=\"Create secret key\" width=\"500\" />\n",
    "\n",
    "1. Copy the API key. WARNING: This is the only time you will be able to see the key. Make sure to save it in a secure location.\n",
    "\n",
    "<img src=\"../assets/tutorials/save_your_key_dialog.png\" alt=\"Save your key\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client\n",
    "\n",
    "You need to set up your OpenAI API key to use the API. Replace `your_api_key` with your actual OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = \"sk-...\"\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview your document\n",
    "\n",
    "We will load the image from a specified path and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image from a path\n",
    "image_path = \"/path/to/image.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode image to url link with base64\n",
    "To send the image to the ChatGPT-4 API, we need to encode the image to a base64 string and then convert it to a URL link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "def encode_image(image: Image.Image) -> str:\n",
    "    \"\"\"Encode an image into base64 format.\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def create_link(base64_image: str) -> str:\n",
    "    \"\"\"Create a link from a base64 image.\"\"\"\n",
    "    return f\"data:image/jpeg;base64,{base64_image}\"\n",
    "\n",
    "\n",
    "# Encode the image\n",
    "encoded_image = encode_image(image)\n",
    "print(\"Base64 image:\", encoded_image)\n",
    "image_link = create_link(encoded_image)\n",
    "print(\"Image link:\", image_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking Questions about the Image\n",
    "\n",
    "We will send a question to the ChatGPT-4 API along with the image to get an answer about its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(image_path: str, question: str) -> str:\n",
    "    \"\"\"Extract information from the image and return the answer.\"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    # Encode the image\n",
    "    encoded_image = encode_image(image)\n",
    "    image_link = create_link(encoded_image)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant designed to extract information from the input document and user question. Please always answer the question based on the information extracted from the document and in a concise manner.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": question,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_link,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "\n",
    "question = \"น้ำหนักรถรวมเท่าไหร่\"\n",
    "answer = extract_information(image_path, question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Information from the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create question prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_question = \"\"\"You are provided with a scanned or photographed image of a Thai vehicle registration book (สมุดทะเบียนรถ). Your task is to extract the following information from the image.The extracted value is typically located on the right side of the key in the document.\n",
    "Extract these details:\n",
    "\n",
    "1. วันจดทะเบียน (date_of_registration)\n",
    "2. เลขทะเบียน (registration_no)\n",
    "3. จังหวัด (car_province)\n",
    "4. ประเภท (vehicle_use)\n",
    "5. รย. (type)\n",
    "6. ลักษณะ (body_style)\n",
    "7. ยี่ห้อรถ (manufacturer)\n",
    "8. แบบ (model)\n",
    "9. รุ่นปี คศ (year)\n",
    "10. สี (color)\n",
    "11. เลขตัวรถ (chassis_number)\n",
    "12. อยู่ที่ (chassis_location)\n",
    "13. ยี่ห้อเครื่องยนต์ (engine_manufacturer)\n",
    "14. เลขเครื่องยนต์ (engine_number)\n",
    "15. อยู่ที่ (engine_location)\n",
    "16. เชื้อเพลิง (fuel_type)\n",
    "17. เลขถังแก๊ส (fuel_tank_number)\n",
    "18. จำนวน (cylinders)\n",
    "19. ซีซี (cubic_capacity)\n",
    "20. แรงม้า (horse_power)\n",
    "21. จำนวนเพลาและล้อ (axles_wheels_no)\n",
    "22. น้ำหนักรถ (unladen_weight)\n",
    "23. น้ำหนักบรรทุก/น้ำหนักเพลา (load_capacity)\n",
    "24. น้ำหนักรวม (gross_weight)\n",
    "25. ที่นั่ง (seats)\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Carefully examine the image and locate each piece of information.\n",
    "If a particular field is not visible or not present in the image, use the value \"N/A\" for that field.\n",
    "Ensure all text extracted from the image is in its original language (Thai or English) as it appears in the document.\n",
    "Return the extracted information in a JSON format, using the English key names provided in parentheses.\n",
    "Only return the JSON output, without any additional explanation or text.\n",
    "\n",
    "Example of expected output format:\n",
    "{\n",
    "  \"date_of_registration\": \"1 ม.ค. 2566\",\n",
    "  \"registration_no\": \"กข 1234\",\n",
    "  \"car_province\": \"กรุงเทพมหานคร\",\n",
    "  ...\n",
    "  \"seats\": \"4\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "answer = extract_information(image_path, extract_question)\n",
    "print(\"Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output from the ChatGPT-4 API can be error sometimes, we will create a clean prompt to ask the model to reformat the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json(json_answer: str) -> str:\n",
    "    \"\"\"Extract information from the image and return the answer.\"\"\"\n",
    "    # Clean prompt\n",
    "    clean_prompt = \"\"\"\n",
    "You are a JSON formatting assistant. Your task is to take a potentially malformed or incomplete JSON string and return a properly formatted, valid JSON object. Follow these steps:\n",
    "\n",
    "1. Analyze the input text for JSON-like structure.\n",
    "2. Identify and correct common JSON formatting errors such as:\n",
    "   - Missing closing braces or brackets\n",
    "   - Trailing commas\n",
    "   - Unquoted keys\n",
    "   - Missing values\n",
    "3. If a value is missing or incomplete, use \"N/A\" as the value.\n",
    "4. Ensure all keys and string values are properly quoted with double quotes.\n",
    "5. Remove any extraneous text before or after the JSON object.\n",
    "6. Format the JSON with proper indentation for readability.\n",
    "\n",
    "Input: {}\n",
    "\n",
    "Instructions:\n",
    "- Return only the corrected JSON object, without any additional explanation or text.\n",
    "- Ensure the output is a complete, valid JSON object that can be parsed by Python's json.loads() function.\n",
    "- Preserve the original data as much as possible, only making changes necessary for valid JSON formatting.\n",
    "\n",
    "Example of expected output format:\n",
    "{{\n",
    "  \"key1\": \"value1\",\n",
    "  \"key2\": \"value2\",\n",
    "  \"key3\": \"N/A\"\n",
    "}}\n",
    "\"\"\"\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # or another suitable model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a JSON formatting assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": clean_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract the cleaned JSON from the response\n",
    "    cleaned_json_str = response.choices[0].message.content\n",
    "    return cleaned_json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to parse the JSON, if it fails, clean it\n",
    "import json\n",
    "\n",
    "\n",
    "def parse_json(answer: str) -> dict:\n",
    "    \"\"\"Parse a JSON string and return a dictionary.\"\"\"\n",
    "    try:\n",
    "        # Remove ```json from the start and end of the string\n",
    "        # and try to parse the JSON\n",
    "        answer = answer.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    except json.JSONDecodeError:\n",
    "        answer = clean_json(answer)\n",
    "    answer = json.loads(answer)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# Parse the JSON\n",
    "answer = parse_json(answer)\n",
    "print(\"Parsed JSON:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run on all images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "extracted_values = []\n",
    "error_paths = []\n",
    "paths = glob(\"/path/to/folder/*.jpg\")\n",
    "for path in tqdm(paths):\n",
    "    answer = extract_information(image_path=path, question=extract_question)\n",
    "    print(f\"path {path} is processed\")\n",
    "    try:\n",
    "        answer = parse_json(answer)\n",
    "        answer[\"image_path\"] = str(Path(path).stem)\n",
    "        extracted_values.append(answer)\n",
    "    except:\n",
    "        error_paths.append(path)\n",
    "        print(f\"Error processing: {path}\")\n",
    "extracted_values_df = pd.DataFrame(extracted_values)\n",
    "extracted_values_df.to_excel(\"predicted_results_chatgpt.xlsx\", index=False)\n",
    "# Preview the DataFrame\n",
    "display(extracted_values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchmetrics.text import CharErrorRate\n",
    "\n",
    "def calculate_cer(preds: list, targets: list):\n",
    "    cer = CharErrorRate() # Initialize the CharErrorRate metric\n",
    "    cer_val = cer(preds, targets) # Calculate CER\n",
    "    return cer_val.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.read_excel('annotated_results.xlsx', dtype=str).fillna(\"\")\n",
    "predicted_df = pd.read_excel('predicted_results_chatgpt.xlsx', dtype=str).fillna(\"\")\n",
    "\n",
    "columns_of_interest = [\n",
    "    'date_of_registration', 'registration_no', 'car_province', 'vehicle_use', 'type', 'body_style',\n",
    "    'manufacturer', 'model', 'year', 'color', 'chassis_number', 'chassis_location', 'engine_manufacturer',\n",
    "    'engine_number', 'engine_location', 'fuel_type', 'fuel_tank_number', 'cylinders', 'cubic_capacity',\n",
    "    'horse_power', 'axles_wheels_no', 'unladen_weight', 'load_capacity', 'gross_weight', 'seats'\n",
    "]\n",
    "merged_df = pd.merge(annotated_df, predicted_df, on='image_path', suffixes=('_annotation', '_prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for col in columns_of_interest:\n",
    "    if f\"{col}_annotation\" in merged_df.columns and f\"{col}_prediction\" in merged_df.columns:\n",
    "        avg_cer = np.mean(calculate_cer(merged_df[f\"{col}_prediction\"], merged_df[f\"{col}_annotation\"]))\n",
    "        avg_accuracy = (merged_df[f\"{col}_prediction\"] == merged_df[f\"{col}_annotation\"]).mean() * 100\n",
    "        eval_list.append({\n",
    "            \"column_name\": col,\n",
    "            \"cer\": avg_cer,\n",
    "            \"accuracy\": avg_accuracy\n",
    "        })\n",
    "eval_df = pd.DataFrame(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eval_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
