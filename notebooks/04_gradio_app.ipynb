{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336756dc-b4b2-4ef8-8b72-b74f72c9a608",
   "metadata": {},
   "source": [
    "## **Make Gradio Application**\n",
    "\n",
    "- Run Ollama on your computer\n",
    "- Create `GoogleVision` class for extract and annotate image\n",
    "- Put all functions together to parse, clean, and extract information in Gradio\n",
    "- Display information in Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa41f68-ea15-4c98-ba3a-0569c30a24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install google cloud vision\n",
    "%%capture\n",
    "!pip install google-cloud\n",
    "!pip install google-cloud-vision\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29325638-aef0-43ee-9958-19ceffbb5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud.vision import ImageAnnotatorClient, Image, EntityAnnotation\n",
    "import PIL.Image as PILImage\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from io import BytesIO\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate # Added\n",
    "\n",
    "FONT = ImageFont.truetype(\"../assets/THSarabun.ttf\", 20)\n",
    "\n",
    "class GoogleVision:\n",
    "    \"\"\"\n",
    "    Google Vision API client\n",
    "\n",
    "    This class allows you to recognize text in an image using Google Vision API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, credential_path: str) -> None:\n",
    "        \"\"\"Create a Google Vision API client using the given credential path\"\"\"\n",
    "        self.client: ImageAnnotatorClient = ImageAnnotatorClient.from_service_account_json(credential_path)\n",
    "\n",
    "    def recognize(self, image: PILImage.Image) -> list[EntityAnnotation]:\n",
    "        \"\"\"Detect bounding box and recognize text in an image from the given PIL image\"\"\"\n",
    "        # Convert PIL image to binary\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        image_binary = buffered.getvalue()\n",
    "        # Construct image object\n",
    "        image = Image(content=image_binary)\n",
    "        # Send request to Google Vision API\n",
    "        response = self.client.text_detection(image)\n",
    "        # Handle error.\n",
    "        if response.error.message:\n",
    "            raise Exception(\n",
    "                f\"{response.error.message}\\nFor more info on error messages, check: https://cloud.google.com/apis/design/errors\"\n",
    "            )\n",
    "        # Get all annotations except the first one (all parsed text)\n",
    "        annotations = [\n",
    "            annotation\n",
    "            for idx, annotation in enumerate(response.text_annotations)\n",
    "            if idx != 0\n",
    "        ]\n",
    "        return annotations\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_bbox(\n",
    "        image: np.array,\n",
    "        annotations: list[EntityAnnotation],\n",
    "        label_offset: int = 20,\n",
    "    ):\n",
    "        \"\"\"Draw bounding box and text on the given image\"\"\"\n",
    "        draw = ImageDraw.Draw(PILImage.fromarray(image))\n",
    "        for annotation in annotations:\n",
    "            # Get information in the annotation\n",
    "            text = annotation.description\n",
    "            vertices = [(vertex.x, vertex.y) for vertex in annotation.bounding_poly.vertices]\n",
    "            # Draw bounding box\n",
    "            draw.polygon(vertices, outline=\"blue\")\n",
    "            # Draw text\n",
    "            draw.text(\n",
    "                (vertices[0][0], vertices[0][1] - label_offset),\n",
    "                text,\n",
    "                fill=\"red\",\n",
    "                font=FONT,\n",
    "            )\n",
    "        return image\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\", stop=[\"<|eot_id|>\"]) # Added stop token\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant expert in returning JSON output from a given prompt.\"\n",
    "\n",
    "def get_model_response(user_prompt, system_prompt=SYSTEM_PROMPT):\n",
    "    # NOTE: No f string and no whitespace in curly braces\n",
    "    template = \"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        {user_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "    # Added prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"system_prompt\", \"user_prompt\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    # Modified invoking the model\n",
    "    response = llm(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def post_process(text):\n",
    "    text = text.replace(\"วัน จดทะเบียน\", \"วันจดทะเบียน\")\n",
    "    text = text.replace(\"เลข ดัง\", \"เลขถัง\")\n",
    "    text = text.replace(\"นํ้า หนัก\", \"น้ำหนัก\")\n",
    "    text = text.replace(\"เลข ทะเบียน\", \"เลขทะเบียน\")\n",
    "    text = text.replace(\"น้ำหนัก บรรทุก\", \"น้ำหนักบรรทุก\")\n",
    "    text = text.replace(\"เลข ที่ บัตร\", \"เลขที่บัตร\")\n",
    "    return text\n",
    "\n",
    "def create_prompt(text):\n",
    "    prompt = f\"\"\"You are an expert in analyzing Thai vehicle registration documents. Your task is to extract specific information from the following OCR text of a Thai vehicle registration document. Please identify and extract the following information, providing the values in Thai where applicable. If a piece of information is not found or unclear, respond with \"ไม่พบข้อมูล\" (Information not found).\n",
    "    \n",
    "    OCR Text: {text}\n",
    "    \n",
    "    Please extract and provide the following information:\n",
    "    \n",
    "    1. วันจดทะเบียน (date_of_registration):\n",
    "    2. เลขทะเบียน (registration_no):\n",
    "    3. จังหวัด (car_province):\n",
    "    4. ประเภท (vehicle_use):\n",
    "    5. รย. (type):\n",
    "    6. ลักษณะ (body_style):\n",
    "    7. ยี่ห้อรถ (manufacturer):\n",
    "    8. แบบ (model):\n",
    "    9. รุ่นปี คศ (year):\n",
    "    10. สี (color):\n",
    "    11. เลขตัวรถ (chassis_number):\n",
    "    12. อยู่ที่ (chassis_location):\n",
    "    13. ยี่ห้อเครื่องยนต์ (engine_manufacturer):\n",
    "    14. เลขเครื่องยนต์ (engine_number):\n",
    "    15. อยู่ที่ (engine_location):\n",
    "    16. เชื้อเพลิง (fuel_type):\n",
    "    17. เลขถังแก๊ส or เลขดังแก๊ส (fuel_tank_number):\n",
    "    18. จำนวน (cylinders):\n",
    "    19. ซีซี (cubic_capacity):\n",
    "    20. แรงม้า (horse_power):\n",
    "    21. จำนวนเพลาและล้อ (axles_wheels_no):\n",
    "    22. น้ำหนักรถ (unladen_weight):\n",
    "    23. น้ำหนักบรรทุก/น้ำหนักเพลา (load_capacity):\n",
    "    24. น้ำหนักรวม (gross_weight):\n",
    "    25. ที่นั่ง (seats):\n",
    "    \n",
    "    Please provide the extracted information in a structured JSON format. Listing each item in a given key with its corresponding value. If information is not found, leave as empty string. Don't need to comment.\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def map_thai_to_english_keys(thai_dict):\n",
    "    # Define the mapping of Thai keys to English keys\n",
    "    key_mapping = {\n",
    "        'วันจดทะเบียน': 'date_of_registration',\n",
    "        'เลขทะเบียน': 'registration_no',\n",
    "        'จังหวัด': 'car_province',\n",
    "        'ประเภท': 'vehicle_use',\n",
    "        'รย.': 'type',\n",
    "        'ลักษณะ': 'body_style',\n",
    "        'ยี่ห้อรถ': 'manufacturer',\n",
    "        'แบบ': 'model',\n",
    "        'รุ่นปี คศ': 'year',\n",
    "        'สี': 'color',\n",
    "        'เลขตัวรถ': 'chassis_number',\n",
    "        'อยู่ที่': 'chassis_location',\n",
    "        'ยี่ห้อเครื่องยนต์': 'engine_manufacturer',\n",
    "        'เลขเครื่องยนต์': 'engine_number',\n",
    "        'เชื้อเพลิง': 'fuel_type',\n",
    "        'เลขถังแก๊ส': 'fuel_tank_number',\n",
    "        'เลขดังแก๊ส': 'fuel_tank_number',  # Alternative key\n",
    "        'จำนวน': 'cylinders',\n",
    "        'ซีซี': 'cubic_capacity',\n",
    "        'แรงม้า': 'horse_power',\n",
    "        'จำนวนเพลาและล้อ': 'axles_wheels_no',\n",
    "        'น้ำหนักรถ': 'unladen_weight',\n",
    "        'น้ำหนักบรรทุก/น้ำหนักเพลา': 'load_capacity',\n",
    "        'น้ำหนักรวม': 'gross_weight',\n",
    "        'ที่นั่ง': 'seats'\n",
    "    }\n",
    "    \n",
    "    # Create a new dictionary with English keys\n",
    "    english_dict = {}\n",
    "    for thai_key, value in thai_dict.items():\n",
    "        if thai_key in key_mapping:\n",
    "            english_key = key_mapping[thai_key]\n",
    "            english_dict[english_key] = value\n",
    "        else:\n",
    "            # If the key is not in our mapping, keep the original key\n",
    "            english_dict[thai_key] = value\n",
    "    \n",
    "    return english_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a9972-b533-455e-bdfd-2b69c48bfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of GoogleVision\n",
    "PATH_TO_CREDENTIAL_JSON = \"../../path_to.json\"\n",
    "api = GoogleVision(PATH_TO_CREDENTIAL_JSON)\n",
    "\n",
    "image = PILImage.open(\"path/to/image.jpg\")\n",
    "annotations = api.recognize(image)  # perfrom OCR\n",
    "extracted_text = \" \".join([anno.description for anno in annotations])  # extract only text\n",
    "extracted_text = post_process(extracted_text)  # simple post-processing\n",
    "\n",
    "prompt = create_prompt(extracted_text)  # Create prompt for getting JSON output\n",
    "output = get_model_response(prompt)  # output in text\n",
    "parsed_json_output = output.split(\"```\")[1] if \"```\" in output else output\n",
    "parsed_json_output = json.loads(output)\n",
    "\n",
    "df = pd.DataFrame.from_dict(parsed_json_output, orient='index', columns=['Value'])\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07432745-bb41-4668-861b-443c261d081f",
   "metadata": {},
   "source": [
    "## **Make Gradio Appplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8a1ec-31f5-4003-918e-31ef54d19441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def perform_ocr(image):\n",
    "    pil_image = PILImage.fromarray(image.astype('uint8'), 'RGB')\n",
    "    annotations = api.recognize(pil_image)\n",
    "    extracted_text = \" \".join([anno.description for anno in annotations])\n",
    "    extracted_text = post_process(extracted_text)\n",
    "    prompt = create_prompt(extracted_text)\n",
    "    output = get_model_response(prompt)\n",
    "    try:\n",
    "        parsed_json_output = output.split(\"```\")[1] if \"```\" in output else output\n",
    "        parsed_json_output = json.loads(output)\n",
    "    except json.JSONDecodeError:\n",
    "        return pd.DataFrame({'Error': ['Failed to parse JSON output']})\n",
    "    df = pd.DataFrame.from_dict(parsed_json_output, orient='index', columns=['Value'])\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    drawn_image = GoogleVision.draw_bbox(image, annotations) # Drawn image\n",
    "    drawn_image_array = np.array(drawn_image)\n",
    "    return df, drawn_image\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=perform_ocr,\n",
    "    inputs=gr.Image(),\n",
    "    outputs=[gr.Dataframe(), gr.Image()],\n",
    "    title=\"OCR and Information Extraction\",\n",
    "    description=\"Upload an image to extract and parse information using Google Vision API and LLM.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d46110",
   "metadata": {},
   "source": [
    "## ฟีเจอร์ที่สามารถเพิ่มเติมได้:\n",
    "\n",
    "ทำได้หลากหลายมาก ตัอวย่างเช่น\n",
    "\n",
    "1. **การดาวน์โหลดผลลัพธ์**\n",
    "   - เพิ่มปุ่มดาวน์โหลดไฟล์ CSV ใช้ `gr.Button`\n",
    "   - และ option การเลือกรูปแบบการดาวน์โหลด (CSV, Excel, JSON) ใช้ `gradio.Radio`\n",
    "\n",
    "2. **การปรับแต่งรูปภาพ**\n",
    "   - เพิ่มเครื่องมือปรับความคมชัด\n",
    "   - เพิ่มการระบบหมุนภาพอัตโนมัติ (ใช้ `deskew`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
