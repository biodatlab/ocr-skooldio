{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806f4d92",
   "metadata": {},
   "source": [
    "## **Prompting with Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image\n",
    "\n",
    "project_name = \"<project-name>\" # ใส่ชื่อ project ที่นี้ ดูชื่อ project name ได้จาก JSON file ที่โหลดมา\n",
    "credentials = service_account.Credentials.from_service_account_file(\"<path>\") # ใส่ path ไปยัง JSON file ที่นี่\n",
    "aiplatform.init(project=project_name, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, model_name=\"gemini-1.5-flash\"):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันสำหรับรับคำตอบจากโมเดล AI\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): คำถามหรือข้อความที่ต้องการให้ AI ตอบ\n",
    "    model_name (str): ชื่อของโมเดลที่ต้องการใช้ (ค่าเริ่มต้นคือ \"gemini-1.5-flash\")\n",
    "    \n",
    "    Returns:\n",
    "    str: ข้อความตอบกลับจาก AI\n",
    "    \"\"\"\n",
    "    model = GenerativeModel(model_name)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70639d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_response(\"Why is sky blue?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdef518",
   "metadata": {},
   "source": [
    "## **Prompt Engineering**\n",
    "\n",
    "Prompt ที่ดีควรจะมีส่วนประกอบดังนี้\n",
    "- Instruction : งานหรือคำสั่งที่ต้องการให้โมเดลทำ\n",
    "- Context : ข้อมูลภายนอกหรือบริบทเพิ่มเติมที่ช่วยให้โมเดลตอบได้ดีขึ้น\n",
    "- Input ข้อมูลหรือคำถามที่เราสนใจหาคำตอบ\n",
    "- Output Indicator : ประเภทหรือรูปแบบของผลลัพธ์ที่ต้องการ เช่น Tone, Length, Style\n",
    "\n",
    "ref: https://www.promptingguide.ai/introduction/elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eec981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "response = get_response(\"Could you list down 5 stunning campaings ideas for my new product launch?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a51e01",
   "metadata": {},
   "source": [
    "## **Multimodal Prompting with Gemini**\n",
    "\n",
    "เราสามารถใช้ Multimodal capability ของ Gemini เพื่อใช้ทำ OCR แบบรวดเร็วเพื่อวัดผลเบื่้องต้นได้\n",
    "\n",
    "อ่านเพิ่มเติม:\n",
    "- https://cloud.google.com/vertex-ai/generative-ai/docs/samples/generativeaionvertexai-gemini-all-modalities#generativeaionvertexai_gemini_all_modalities-python\n",
    "- https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.vision_models.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0280412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_with_image(prompt, image_path, model_name=\"gemini-pro-vision\"):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันสำหรับรับคำตอบจากโมเดล AI โดยใช้รูปภาพประกอบ\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): คำถามหรือข้อความที่ต้องการให้ AI ตอบ\n",
    "    image_path (str): พาธของไฟล์รูปภาพ\n",
    "    model_name (str): ชื่อของโมเดลที่ต้องการใช้ (ค่าเริ่มต้นคือ \"gemini-pro-vision\")\n",
    "    \n",
    "    Returns:\n",
    "    str: ข้อความตอบกลับจาก AI\n",
    "    \"\"\"\n",
    "\n",
    "    model = GenerativeModel(model_name)\n",
    "    image = Image.load_from_file(image_path)\n",
    "\n",
    "    # สร้างคำตอบจากโมเดล\n",
    "    response = model.generate_content([image, prompt])\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Perform optical character information and export in the following JSON format.\n",
    "\n",
    "{\n",
    "  tax_id: str,\n",
    "  pos_id: str,\n",
    "  tel_number: str,\n",
    "  date: str,\n",
    "  recepit_number: str,\n",
    "  items: list[name, float],\n",
    "  price_before_vat: float,\n",
    "  total_price: float,\n",
    "  vat_7_percent: float,\n",
    "  earn_point: float\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "answer = get_response_with_image(prompt, \"../assets/seki_example.jpg\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
