{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install google cloud vision\n",
    "!pip install google-cloud\n",
    "!pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Google Cloud Project\n",
    "\n",
    "### Step 1: Create a Google Cloud Project\n",
    "Go to the [Google Cloud Console](https://console.cloud.google.com/projectcreate) and create a new project.\n",
    "### Step 2: Enable Cloud Vision API\n",
    "Go to the [Google Vision Wizard Page](https://console.cloud.google.com/apis/credentials/wizard?api=vision.googleapis.com), create a new service account to allow us to access the Cloud Vision API.\n",
    "### Step 3: Create credential JSON key\n",
    "After creating the service account, click on the service account and go to the `Keys` tab. Click on `Add Key` and `Create new key`.\n",
    "### Step 4: Download JSON key\n",
    "The key should be automatically downloaded. This file should be named like `<project_id>-<hash>.json` for example `my-project-1234567890abcdef.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define interface for Google Cloud Vision API\n",
    "\n",
    "Create an GoogleVision class to send image to Google Cloud Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud.vision import ImageAnnotatorClient, Image, EntityAnnotation\n",
    "import PIL.Image as PILImage\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from io import BytesIO\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate # Added\n",
    "\n",
    "FONT = ImageFont.truetype(\"../assets/THSarabun.ttf\", 20)\n",
    "\n",
    "\n",
    "class GoogleVision:\n",
    "    \"\"\"\n",
    "    Google Vision API client\n",
    "\n",
    "    This class allows you to recognize text in an image using Google Vision API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, credential_path: str) -> None:\n",
    "        \"\"\"Create a Google Vision API client using the given credential path\"\"\"\n",
    "        self.client: ImageAnnotatorClient = ImageAnnotatorClient.from_service_account_json(credential_path)\n",
    "\n",
    "    def recognize(self, image: PILImage.Image) -> list[EntityAnnotation]:\n",
    "        \"\"\"Detect bounding box and recognize text in an image from the given PIL image\"\"\"\n",
    "        # Convert PIL image to binary\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        image_binary = buffered.getvalue()\n",
    "        # Construct image object\n",
    "        image = Image(content=image_binary)\n",
    "        # Send request to Google Vision API\n",
    "        response = self.client.text_detection(image)\n",
    "        # Handle error.\n",
    "        if response.error.message:\n",
    "            raise Exception(\n",
    "                f\"{response.error.message}\\nFor more info on error messages, check: https://cloud.google.com/apis/design/errors\"\n",
    "            )\n",
    "        # Get all annotations except the first one (all parsed text)\n",
    "        annotations = [\n",
    "            annotation\n",
    "            for idx, annotation in enumerate(response.text_annotations)\n",
    "            if idx != 0\n",
    "        ]\n",
    "        return annotations\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_bbox(\n",
    "        image: PILImage.Image,\n",
    "        annotations: list[EntityAnnotation],\n",
    "        label_offset: int = 20,\n",
    "    ):\n",
    "        \"\"\"Draw bounding box and text on the given image\"\"\"\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for annotation in annotations:\n",
    "            # Get information in the annotation\n",
    "            text = annotation.description\n",
    "            vertices = [(vertex.x, vertex.y) for vertex in annotation.bounding_poly.vertices]\n",
    "            # Draw bounding box\n",
    "            draw.polygon(vertices, outline=\"blue\")\n",
    "            # Draw text\n",
    "            draw.text(\n",
    "                (vertices[0][0], vertices[0][1] - label_offset),\n",
    "                text,\n",
    "                fill=\"red\",\n",
    "                font=FONT,\n",
    "            )\n",
    "        return image\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\", stop=[\"<|eot_id|>\"]) # Added stop token\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant expert in returning JSON output from a given prompt.\"\n",
    "\n",
    "def get_model_response(user_prompt, system_prompt=SYSTEM_PROMPT):\n",
    "    # NOTE: No f string and no whitespace in curly braces\n",
    "    template = \"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        {user_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "    # Added prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"system_prompt\", \"user_prompt\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    # Modified invoking the model\n",
    "    response = llm(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of GoogleVision\n",
    "PATH_TO_CREDENTIAL_JSON = \"../path/to/credentials.json\"\n",
    "api = GoogleVision(PATH_TO_CREDENTIAL_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We load the receipt to run text detection and recognition on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"path/to/.jpg\"\n",
    "image = PILImage.open(path).convert(\"RGB\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the receipt to the Google Cloud Vision API to extract the text from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = api.recognize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_image = GoogleVision.draw_bbox(image, annotations)\n",
    "display(drawn_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse extracted OCR text and prompt for JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = \" \".join([anno.description for anno in annotations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(text):\n",
    "    text = text.replace(\"เลข ดัง\", \"เลขถัง\")\n",
    "    text = text.replace(\"นํ้า หนัก\", \"น้ำหนัก\")\n",
    "    text = text.replace(\"เลข ทะเบียน\", \"เลขทะเบียน\")\n",
    "    return text\n",
    "\n",
    "plain_text = post_process(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text):\n",
    "    prompt = f\"\"\"You are an expert in analyzing Thai vehicle registration documents. Your task is to extract specific information from the following OCR text of a Thai vehicle registration document. Please identify and extract the following information, providing the values in Thai where applicable. If a piece of information is not found or unclear, respond with \"ไม่พบข้อมูล\" (Information not found).\n",
    "    \n",
    "    OCR Text: {text}\n",
    "    \n",
    "    Please extract and provide the following information:\n",
    "    \n",
    "    1. วันจดทะเบียน (date_of_registration):\n",
    "    2. เลขทะเบียน (registration_no):\n",
    "    3. จังหวัด (car_province):\n",
    "    4. ประเภท (vehicle_use):\n",
    "    5. รย. (type):\n",
    "    6. ลักษณะ (body_style):\n",
    "    7. ยี่ห้อรถ (manufacturer):\n",
    "    8. แบบ (model):\n",
    "    9. รุ่นปี คศ (year):\n",
    "    10. สี (color):\n",
    "    11. เลขตัวรถ (chassis_number):\n",
    "    12. อยู่ที่ (chassis_location):\n",
    "    13. ยี่ห้อเครื่องยนต์ (engine_manufacturer):\n",
    "    14. เลขเครื่องยนต์ (engine_number):\n",
    "    15. อยู่ที่ (engine_location):\n",
    "    16. เชื้อเพลิง (fuel_type):\n",
    "    17. เลขถังแก๊ส or เลขดังแก๊ส (fuel_tank_number):\n",
    "    18. จำนวน (cylinders):\n",
    "    19. ซีซี (cubic_capacity):\n",
    "    20. แรงม้า (horse_power):\n",
    "    21. จำนวนเพลาและล้อ (axles_wheels_no):\n",
    "    22. น้ำหนักรถ (unladen_weight):\n",
    "    23. น้ำหนักบรรทุก/น้ำหนักเพลา (load_capacity):\n",
    "    24. น้ำหนักรวม (gross_weight):\n",
    "    25. ที่นั่ง (seats):\n",
    "    \n",
    "    Please provide the extracted information in a structured JSON format. Listing each item in a given key with its corresponding value. If information is not found, leave as empty string. Don't need to comment.\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt(plain_text)\n",
    "output = get_model_response(prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_json_output = json.loads(output.split(\"```\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_thai_to_english_keys(thai_dict):\n",
    "    # Define the mapping of Thai keys to English keys\n",
    "    key_mapping = {\n",
    "        'วันจดทะเบียน': 'date_of_registration',\n",
    "        'เลขทะเบียน': 'registration_no',\n",
    "        'จังหวัด': 'car_province',\n",
    "        'ประเภท': 'vehicle_use',\n",
    "        'รย.': 'type',\n",
    "        'ลักษณะ': 'body_style',\n",
    "        'ยี่ห้อรถ': 'manufacturer',\n",
    "        'แบบ': 'model',\n",
    "        'รุ่นปี คศ': 'year',\n",
    "        'สี': 'color',\n",
    "        'เลขตัวรถ': 'chassis_number',\n",
    "        'อยู่ที่': 'chassis_location',\n",
    "        'ยี่ห้อเครื่องยนต์': 'engine_manufacturer',\n",
    "        'เลขเครื่องยนต์': 'engine_number',\n",
    "        'เชื้อเพลิง': 'fuel_type',\n",
    "        'เลขถังแก๊ส': 'fuel_tank_number',\n",
    "        'เลขดังแก๊ส': 'fuel_tank_number',  # Alternative key\n",
    "        'จำนวน': 'cylinders',\n",
    "        'ซีซี': 'cubic_capacity',\n",
    "        'แรงม้า': 'horse_power',\n",
    "        'จำนวนเพลาและล้อ': 'axles_wheels_no',\n",
    "        'น้ำหนักรถ': 'unladen_weight',\n",
    "        'น้ำหนักบรรทุก/น้ำหนักเพลา': 'load_capacity',\n",
    "        'น้ำหนักรวม': 'gross_weight',\n",
    "        'ที่นั่ง': 'seats'\n",
    "    }\n",
    "    \n",
    "    # Create a new dictionary with English keys\n",
    "    english_dict = {}\n",
    "    for thai_key, value in thai_dict.items():\n",
    "        if thai_key in key_mapping:\n",
    "            english_key = key_mapping[thai_key]\n",
    "            english_dict[english_key] = value\n",
    "        else:\n",
    "            # If the key is not in our mapping, keep the original key\n",
    "            english_dict[thai_key] = value\n",
    "    \n",
    "    return english_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_json_output_eng = map_thai_to_english_keys(parsed_json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_json_output_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull all together: run on sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "extracted_values = []\n",
    "paths = glob(\"path/to/*.jpg\")\n",
    "for path in tqdm(paths):\n",
    "    try:\n",
    "        image = PILImage.open(path).convert(\"RGB\")\n",
    "        # Google API\n",
    "        annotations = api.recognize(image)\n",
    "        plain_text = \" \".join([anno.description for anno in annotations])\n",
    "        # Prompt\n",
    "        prompt = create_prompt(plain_text)\n",
    "        output = get_model_response(prompt)\n",
    "        output = output.split(\"```\")[1] if \"```\" in output else output\n",
    "        parsed_json_output = json.loads(output)\n",
    "        parsed_json_output_eng = map_thai_to_english_keys(parsed_json_output)\n",
    "        parsed_json_output_eng[\"path\"] = Path(path).stem\n",
    "        extracted_values.append(parsed_json_output_eng)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"JSON decoding error for path: {path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing path: {path}, Error: {e}\")\n",
    "\n",
    "extracted_values_df = pd.DataFrame(extracted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_values_df[\"image_path\"] = [Path(p).stem for p in paths]\n",
    "extracted_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'predicted_results_google_ocr.xlsx'\n",
    "extracted_values_df.to_excel(output_file, index=False)\n",
    "print(f\"DataFrame saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "อ่านผลของแต่ละ key และวัดประสิทธิภาพด้วย CER และ Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchmetrics.text import CharErrorRate\n",
    "\n",
    "def calculate_cer(preds: list, targets: list):\n",
    "    cer = CharErrorRate() # Initialize the CharErrorRate metric\n",
    "    cer_val = cer(preds, targets) # Calculate CER\n",
    "    return cer_val.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.read_excel('annotated_results.xlsx', dtype=str).fillna(\"\")\n",
    "predicted_df = pd.read_excel('predicted_results_google_ocr.xlsx', dtype=str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df[\"year\"] = predicted_df[\"year\"].map(lambda x: x.replace(\"ไม่พบข้อมูล\", \"\"))\n",
    "annotated_df[\"year\"] = annotated_df[\"year\"].map(lambda x: x.replace(\"ไม่พบข้อมูล\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'date_of_registration', 'registration_no', 'car_province', 'vehicle_use', 'type', 'body_style',\n",
    "    'manufacturer', 'model', 'year', 'color', 'chassis_number', 'chassis_location', 'engine_manufacturer',\n",
    "    'engine_number', 'engine_location', 'fuel_type', 'fuel_tank_number', 'cylinders', 'cubic_capacity',\n",
    "    'horse_power', 'axles_wheels_no', 'unladen_weight', 'load_capacity', 'gross_weight', 'seats'\n",
    "]\n",
    "merged_df = pd.merge(annotated_df, predicted_df, on='image_path', suffixes=('_annotation', '_prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"car_province\" # col = \"date_of_registration\"\n",
    "merged_df[[f\"{col}_annotation\", f\"{col}_prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for col in columns_of_interest:\n",
    "    if f\"{col}_annotation\" in merged_df.columns and f\"{col}_prediction\" in merged_df.columns:\n",
    "        avg_cer = np.mean(calculate_cer(merged_df[f\"{col}_prediction\"], merged_df[f\"{col}_annotation\"]))\n",
    "        avg_accuracy = (merged_df[f\"{col}_prediction\"] == merged_df[f\"{col}_annotation\"]).mean() * 100\n",
    "        eval_list.append({\n",
    "            \"column_name\": col,\n",
    "            \"cer\": avg_cer,\n",
    "            \"accuracy\": avg_accuracy\n",
    "        })\n",
    "eval_df = pd.DataFrame(eval_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "- ถ่ายภาพใบเสร็จที่ให้\n",
    "- จากนั้นรัน `annotations = api.recognize(image)`\n",
    "- เขียน prompt เพื่อดึงรายการที่สั่งและราคารวมออกมาในรูปแบบ JSON\n",
    "- จากนั้นรัน `output = get_model_response(prompt)` เพื่อดึงข้อมูลออกมาในรูปแบบ JSON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
