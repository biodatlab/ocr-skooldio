{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# การประเมินผล OCR (Optical Character Recognition)\n",
    "\n",
    "โน้ตบุ๊กนี้แสดงวิธีการประเมินประสิทธิภาพของระบบ OCR โดยใช้ตัวชี้วัดสองตัว:\n",
    "\n",
    "- CER (Character Error Rate) หรืออัตราความผิดพลาดระดับตัวอักษร\n",
    "- ความแม่นยำ (Accuracy)\n",
    "\n",
    "## ติดตั้งไลบรารีที่จำเป็น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "นำเข้าไลบรารีและการกำหนดฟังก์ชัน\n",
    "\n",
    "- สร้างคลาส `CharErrorRate` และ คำนวณความผิดพลาด\n",
    "- หรือใช้ฟังก์ชั่น `char_error_rate` เพื่อคำนวณ CER โดยตรง\n",
    "- สำหรับ accuracy สามารถใช้ `==` เพื่อเทียบ string 2 ตัวได้เลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.text import CharErrorRate\n",
    "\n",
    "def calculate_cer(preds: list, targets: list):\n",
    "    cer = CharErrorRate() # Initialize the CharErrorRate metric\n",
    "    cer_val = cer(preds, targets) # Calculate CER\n",
    "    return cer_val.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\"สวัสดีครับ ยินดีต้อนรับ\"]\n",
    "targets = [\"สวัสดีคับ ยินดีต้อนรบ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer = calculate_cer(preds, targets)\n",
    "print(f\"Character Error Rate (CER): {cer:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use the build-in function to calculate CER\n",
    "from torchmetrics.functional.text import char_error_rate\n",
    "\n",
    "cer_rate = char_error_rate(preds, targets)\n",
    "print(f\"\\nDetailed CER calculation: {cer_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [int(pred == target) for pred, target\n",
    "            in zip(preds, targets)]  # 1 if the strings are equal, 0 otherwise\n",
    "print(f\"\\nAccuracy: {np.mean(accuracy)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
